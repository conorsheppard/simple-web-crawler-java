version: '3.8'

services:
  redis-web-crawler:
    image: redis:latest
    container_name: redis-web-crawler
    ports:
      - "6379:6379"
    networks:
      - crawler-network

  kafka-web-crawler:
    image: apache/kafka:4.0.0
    container_name: kafka-web-crawler
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-web-crawler:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka-web-crawler:9093
      KAFKA_CONTROLLER_QUORUM_BOOTSTRAP_SERVERS: CONTROLLER://kafka-web-crawler:9093
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      KAFKA_CONFLUENT_SUPPORT_METRICS_ENABLE: "false"
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_LOG4J_LOGGERS: "kafka.controller=ERROR,kafka.producer.async.DefaultEventHandler=ERROR,state.change.logger=ERROR"
    ports:
      - "9092:9092"  # Broker port
      - "9093:9093"  # Controller port
    networks:
      - crawler-network
    volumes:
      - ./kafka/data:/var/lib/kafka/data
    depends_on:
      redis-web-crawler:
        condition: service_started
    healthcheck:
      test: [ "CMD", "/opt/kafka/bin/kafka-topics.sh", "--list", "--bootstrap-server", "kafka-web-crawler:9092" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
#    command: [ "/bin/sh", "-c", "kafka-server-start.sh config/kraft/server.properties >/dev/null 2>&1" ]

  simple-web-crawler-java:
    image: conorsheppard/simple-web-crawler-java:latest
    container_name: simple-web-crawler-java
    depends_on:
      kafka-web-crawler:
        condition: service_healthy
      redis-web-crawler:
        condition: service_started
    networks:
      - crawler-network
    stdin_open: true
    tty: true
    restart: "no"
    environment:
      - CRAWLER_ARGS=${ARGS}
#    command: [ "$CRAWLER_ARGS" ]

networks:
  crawler-network:
    driver: bridge
